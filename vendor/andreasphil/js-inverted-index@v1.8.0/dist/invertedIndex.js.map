{
  "version": 3,
  "sources": ["../src/invertedIndex.js"],
  "sourcesContent": ["/* -------------------------------------------------- *\n * Types                                              *\n * -------------------------------------------------- */\n\n/**\n * Specifies a nested property inside an object.\n *\n * @typedef {string | string[]} PropPath\n */\n\n/**\n * Strings or stuff that can be converted into a string.\n *\n * @typedef {string | { toString: () => string }} Stringable\n */\n\n/**\n * Documents that can be added to the search index.\n *\n * @typedef {Record<string, unknown>} Searchable\n */\n\n/**\n * Mapping of search terms to the IDs of matching documents.\n *\n * @typedef {Record<string, Set<string>>} SearchIndex\n */\n\n/**\n * Search index with an ID array instead of a set (for JSON serialization).\n *\n * @typedef {Record<string, string[]>} SearchIndexDump\n */\n\n/**\n * Takes a document and returns a value that can be used for uniquely\n * identifying the document.\n *\n * @template {Searchable} [T = any]\n * @template [U = string]\n * @callback IdentifierFn\n * @param {T} document Original document\n * @returns {U} Identifier of the document\n */\n\n/**\n * Takes a string and splits it into individual tokens. These tokens will be\n * used for building the search index.\n *\n * @callback TokenizerFn\n * @param {string} input Source string\n * @returns {string[]} Tokens found in the source string\n */\n\n/**\n * Takes a string and returns it in a normalized format, e.g. converts it to\n * lowercase and trim leading/trailing whitespace.\n *\n * @callback NormalizerFn\n * @param {string} input Source string\n * @returns {string} Normalized string\n */\n\n/**\n * Takes and index and returns all search results for the specified term. Calls\n * to the function will also use the original indexing options. These can be\n * used for normalizing and tokenizing the search term in the same way the\n * documents in the index are in order to make matches more likely.\n *\n * @callback SearcherFn\n * @param {SearchIndex} index Index to search in\n * @param {string} term Term to search for\n * @param {IndexingOptions} options Options used for generating the index\n * @returns {Set<string>} Set of IDs of documents matching the term\n */\n\n/**\n * Specifies configuration for building a search index.\n *\n * @typedef IndexingOptions\n * @prop {IdentifierFn} identifier Strategy for extracting an ID from a document.\n * @prop {TokenizerFn} tokenizer Strategy for splitting a value of a document into tokens.\n * @prop {NormalizerFn} normalizer Strategy for normalizing the format of the tokens.\n * @prop {SearcherFn} searcher Strategy for looking up terms in the index.\n * @prop {PropPath[]} fields An array containing the properties that should be indexed.\n */\n\n/**\n * The closure returned when the search has been initialized. Contains methods\n * for interacting with the index, such as adding documents or searching.\n *\n * @template {Searchable} T\n * @typedef Search\n * @prop {(term: string) => T[]} search\n * @prop {(documents: T[]) => void} add\n * @prop {() => SearchIndexDump} dump\n * @prop {(index: SearchIndexDump, documents: T[]) => void} hydrate\n */\n\n/* -------------------------------------------------- *\n * Helpers                                            *\n * -------------------------------------------------- */\n\n/**\n * Recursively reads the value of a property from nested object structures. For\n * example:\n *\n * getNestedProp({ a: { b: 'value' }}, 'a.b') // => 'value'\n * getNestedProp({ a: { b: 'value' }}, ['a', 'b']) // => 'value'\n *\n * @param {Record<string, any>} obj\n * @param {PropPath} prop\n * @returns {Stringable | undefined}\n */\nexport function unwrap(obj, prop) {\n  if (!obj) return undefined;\n\n  const path = Array.isArray(prop) ? prop : prop.split(\".\");\n  const [head, ...tail] = path;\n\n  if (tail.length) return unwrap(obj[head], tail);\n  else return obj[head];\n}\n\n/**\n * Returns the intersection of multiple sets.\n *\n * @template T\n * @param {Set<T>[]} sets Sets to get common elements from\n * @returns {Set<T>} Set containing the elements shared among the source sets\n */\nexport function intersect(...sets) {\n  if (!sets.length || sets.some((set) => !set)) return new Set();\n  else if (sets.length === 1) return sets[0];\n\n  const setsCopy = [...sets];\n  const a = setsCopy.shift();\n  const b = setsCopy.shift();\n  const intersection = new Set();\n\n  a.forEach((itemFromA) => {\n    if (b.has(itemFromA)) intersection.add(itemFromA);\n  });\n\n  setsCopy.unshift(intersection);\n\n  return intersect(...setsCopy);\n}\n\n/**\n * Identifies documents by the value of a property.\n *\n * @template {Record<string, any>} T\n * @param {keyof T} prop\n * @returns {IdentifierFn<T>}\n */\nexport function idProp(prop) {\n  return (document) => document[prop]?.toString?.();\n}\n\n/* -------------------------------------------------- *\n * Normalizers                                        *\n * -------------------------------------------------- */\n\n/**\n * Removes leading/trailing whitespace and converts the value to lowercase.\n * @type {NormalizerFn}\n */\nexport const lowercaseTrim = (input) => input?.trim().toLowerCase();\n\n/* -------------------------------------------------- *\n * Matchers                                           *\n * -------------------------------------------------- */\n\n/**\n * Looks up all ID entries in the index for a search term. The search term is\n * split according to the provided matcher expression. If the term consists of\n * multiple words, only results containing all words are returned.\n *\n * @type {SearcherFn}\n */\nexport const matchAllTerms = (index, term, options) => {\n  if (!term || Object.keys(index).length === 0) {\n    return new Set();\n  }\n\n  const { tokenizer, normalizer } = options;\n  const termTokens = tokenizer(term).map((token) => normalizer(token));\n  const matches = termTokens.map((token) => index[token]);\n\n  return intersect(...matches);\n};\n\n/* -------------------------------------------------- *\n * Tokenizers                                         *\n * -------------------------------------------------- */\n\n/**\n * Returns a new tokenizer that splits a value based on the specified regex.\n *\n * @param {RegExp} exp\n * @returns {TokenizerFn}\n */\nexport function regexSplit(exp) {\n  return (input) => (input ? input.match(exp) || [] : []);\n}\n\n/**\n * Returns a tokenizer that splits values on word boundaries.\n */\nexport const fullWordSplit = regexSplit(/\\w+/g);\n\n/**\n * Returns a tokenizer that returns the word itself as well as anything that\n * that would return true if used with `startsWith`, e.g. for dog, return d,\n * do, and dog.\n *\n * @type {TokenizerFn}\n */\nexport const startsWith = (input) => {\n  const inputWords = fullWordSplit(input);\n  const tokens = new Set();\n\n  inputWords\n    .filter((word) => word.length > 0)\n    .forEach((word) => {\n      for (let i = 1; i <= word.length; i++) {\n        tokens.add(word.substring(0, i));\n      }\n    });\n\n  return Array.from(tokens);\n};\n\n/* -------------------------------------------------- *\n * Search index                                       *\n * -------------------------------------------------- */\n\n/**\n * Creates a new search index and returns functions for interacting with it.\n *\n * @template {Searchable} T\n * @param {Partial<IndexingOptions>} [options={}]\n * @returns {Search<T>}\n */\nexport default function createSearch(options = {}) {\n  // Merge custom and default options\n  /** @type {IndexingOptions} */\n  const effectiveOptions = {\n    tokenizer: fullWordSplit,\n    identifier: idProp(\"id\"),\n    normalizer: lowercaseTrim,\n    searcher: matchAllTerms,\n    fields: [],\n    ...options,\n  };\n\n  /**\n   * Map of possible search terms -> document IDs\n   * @type {SearchIndex}\n   */\n  let index = Object.create(null);\n\n  /**\n   * Map of document IDs -> original documents\n   * @type {Record<string, T>}\n   */\n  let indexedDocuments = {};\n\n  /** @type {Search<T>[\"search\"]} */\n  const search = (term) => {\n    /** @type {T[]} */\n    const matches = [];\n    const idMatches = effectiveOptions.searcher(index, term, effectiveOptions);\n    idMatches.forEach((id) => {\n      if (indexedDocuments[id]) matches.push(indexedDocuments[id]);\n    });\n\n    return matches;\n  };\n\n  /** @type {Search<T>[\"add\"]} */\n  const add = (documents) => {\n    const { tokenizer, identifier, normalizer, fields } = effectiveOptions;\n\n    documents.forEach((document) => {\n      const id = identifier(document);\n      indexedDocuments[id] = document;\n\n      fields\n        .map((path) => unwrap(document, path))\n        .filter(/** @returns {value is Stringable} */ (value) =>\n          !!value?.toString\n        )\n        .flatMap((value) => tokenizer(value.toString()))\n        .map((token) => normalizer(token))\n        .forEach((token) => {\n          if (index[token]) index[token].add(id);\n          else index[token] = new Set([id]);\n        });\n    });\n  };\n\n  /** @type {Search<T>[\"dump\"]} */\n  const dump = () => {\n    /** @type {SearchIndexDump} */\n    const dumpInit = {};\n\n    return Object.entries(index).reduce((all, [k, v]) => {\n      all[k] = Array.from(v);\n      return all;\n    }, dumpInit);\n  };\n\n  /** @type {Search<T>[\"hydrate\"]} */\n  const hydrate = (dump, documents) => {\n    /** @type {SearchIndex} */\n    const indexInit = {};\n\n    /** @type {Record<string, T>} */\n    const documentsInit = {};\n\n    index = Object.entries(dump).reduce((all, [k, v]) => {\n      all[k] = new Set(v);\n      return all;\n    }, indexInit);\n\n    indexedDocuments = documents.reduce((all, i) => {\n      all[effectiveOptions.identifier(i)] = i;\n      return all;\n    }, documentsInit);\n  };\n\n  return { search, add, dump, hydrate };\n}\n"],
  "mappings": "AAkHO,SAASA,EAAOC,EAAKC,EAAM,CAChC,GAAI,CAACD,EAAK,OAEV,IAAME,EAAO,MAAM,QAAQD,CAAI,EAAIA,EAAOA,EAAK,MAAM,GAAG,EAClD,CAACE,EAAM,GAAGC,CAAI,EAAIF,EAExB,OAAIE,EAAK,OAAeL,EAAOC,EAAIG,CAAI,EAAGC,CAAI,EAClCJ,EAAIG,CAAI,CACtB,CASO,SAASE,KAAaC,EAAM,CACjC,GAAI,CAACA,EAAK,QAAUA,EAAK,KAAMC,GAAQ,CAACA,CAAG,EAAG,OAAO,IAAI,IACpD,GAAID,EAAK,SAAW,EAAG,OAAOA,EAAK,CAAC,EAEzC,IAAME,EAAW,CAAC,GAAGF,CAAI,EACnBG,EAAID,EAAS,MAAM,EACnBE,EAAIF,EAAS,MAAM,EACnBG,EAAe,IAAI,IAEzB,OAAAF,EAAE,QAASG,GAAc,CACnBF,EAAE,IAAIE,CAAS,GAAGD,EAAa,IAAIC,CAAS,CAClD,CAAC,EAEDJ,EAAS,QAAQG,CAAY,EAEtBN,EAAU,GAAGG,CAAQ,CAC9B,CASO,SAASK,EAAOZ,EAAM,CAC3B,OAAQa,GAAaA,EAASb,CAAI,GAAG,WAAW,CAClD,CAUO,IAAMc,EAAiBC,GAAUA,GAAO,KAAK,EAAE,YAAY,EAarDC,EAAgB,CAACC,EAAOC,EAAMC,IAAY,CACrD,GAAI,CAACD,GAAQ,OAAO,KAAKD,CAAK,EAAE,SAAW,EACzC,OAAO,IAAI,IAGb,GAAM,CAAE,UAAAG,EAAW,WAAAC,CAAW,EAAIF,EAE5BG,EADaF,EAAUF,CAAI,EAAE,IAAKK,GAAUF,EAAWE,CAAK,CAAC,EACxC,IAAKA,GAAUN,EAAMM,CAAK,CAAC,EAEtD,OAAOnB,EAAU,GAAGkB,CAAO,CAC7B,EAYO,SAASE,EAAWC,EAAK,CAC9B,OAAQV,GAAWA,EAAQA,EAAM,MAAMU,CAAG,GAAK,CAAC,EAAI,CAAC,CACvD,CAKO,IAAMC,EAAgBF,EAAW,MAAM,EASjCG,EAAcZ,GAAU,CACnC,IAAMa,EAAaF,EAAcX,CAAK,EAChCc,EAAS,IAAI,IAEnB,OAAAD,EACG,OAAQE,GAASA,EAAK,OAAS,CAAC,EAChC,QAASA,GAAS,CACjB,QAAS,EAAI,EAAG,GAAKA,EAAK,OAAQ,IAChCD,EAAO,IAAIC,EAAK,UAAU,EAAG,CAAC,CAAC,CAEnC,CAAC,EAEI,MAAM,KAAKD,CAAM,CAC1B,EAae,SAARE,EAA8BZ,EAAU,CAAC,EAAG,CAGjD,IAAMa,EAAmB,CACvB,UAAWN,EACX,WAAYd,EAAO,IAAI,EACvB,WAAYE,EACZ,SAAUE,EACV,OAAQ,CAAC,EACT,GAAGG,CACL,EAMIF,EAAQ,OAAO,OAAO,IAAI,EAM1BgB,EAAmB,CAAC,EAkExB,MAAO,CAAE,OA/DOf,GAAS,CAEvB,IAAMI,EAAU,CAAC,EAEjB,OADkBU,EAAiB,SAASf,EAAOC,EAAMc,CAAgB,EAC/D,QAASE,GAAO,CACpBD,EAAiBC,CAAE,GAAGZ,EAAQ,KAAKW,EAAiBC,CAAE,CAAC,CAC7D,CAAC,EAEMZ,CACT,EAsDiB,IAnDJa,GAAc,CACzB,GAAM,CAAE,UAAAf,EAAW,WAAAgB,EAAY,WAAAf,EAAY,OAAAgB,CAAO,EAAIL,EAEtDG,EAAU,QAAStB,GAAa,CAC9B,IAAMqB,EAAKE,EAAWvB,CAAQ,EAC9BoB,EAAiBC,CAAE,EAAIrB,EAEvBwB,EACG,IAAKpC,GAASH,EAAOe,EAAUZ,CAAI,CAAC,EACpC,OAA8CqC,GAC7C,CAAC,CAACA,GAAO,QACX,EACC,QAASA,GAAUlB,EAAUkB,EAAM,SAAS,CAAC,CAAC,EAC9C,IAAKf,GAAUF,EAAWE,CAAK,CAAC,EAChC,QAASA,GAAU,CACdN,EAAMM,CAAK,EAAGN,EAAMM,CAAK,EAAE,IAAIW,CAAE,EAChCjB,EAAMM,CAAK,EAAI,IAAI,IAAI,CAACW,CAAE,CAAC,CAClC,CAAC,CACL,CAAC,CACH,EAgCsB,KA7BT,IAAM,CAEjB,IAAMK,EAAW,CAAC,EAElB,OAAO,OAAO,QAAQtB,CAAK,EAAE,OAAO,CAACuB,EAAK,CAACC,EAAGC,CAAC,KAC7CF,EAAIC,CAAC,EAAI,MAAM,KAAKC,CAAC,EACdF,GACND,CAAQ,CACb,EAqB4B,QAlBZ,CAACI,EAAMR,IAAc,CAEnC,IAAMS,EAAY,CAAC,EAGbC,EAAgB,CAAC,EAEvB5B,EAAQ,OAAO,QAAQ0B,CAAI,EAAE,OAAO,CAACH,EAAK,CAACC,EAAGC,CAAC,KAC7CF,EAAIC,CAAC,EAAI,IAAI,IAAIC,CAAC,EACXF,GACNI,CAAS,EAEZX,EAAmBE,EAAU,OAAO,CAACK,EAAKM,KACxCN,EAAIR,EAAiB,WAAWc,CAAC,CAAC,EAAIA,EAC/BN,GACNK,CAAa,CAClB,CAEoC,CACtC",
  "names": ["unwrap", "obj", "prop", "path", "head", "tail", "intersect", "sets", "set", "setsCopy", "a", "b", "intersection", "itemFromA", "idProp", "document", "lowercaseTrim", "input", "matchAllTerms", "index", "term", "options", "tokenizer", "normalizer", "matches", "token", "regexSplit", "exp", "fullWordSplit", "startsWith", "inputWords", "tokens", "word", "createSearch", "effectiveOptions", "indexedDocuments", "id", "documents", "identifier", "fields", "value", "dumpInit", "all", "k", "v", "dump", "indexInit", "documentsInit", "i"]
}
